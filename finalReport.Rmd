---
title:    "Survival Analysis of Worsening Hypertension"
subtitle: "PSTAT 196 Report"
author:   "John Randazzo, Jason Freeberg, Ziyi Jiang"
date:     "4/16/2017"
output:   pdf_document
---

```{r, echo=F, message=F}

# Libraries
library(ggplot2)
library(survival)
library(plyr)
library(dplyr)
library(knitr)
library(xtable)
options(xtable.floating = FALSE)
options(xtable.timestamp = "")
options(xtable.comment = FALSE)

# Function to create nice Survival Curves
# From: https://www.r-statistics.com/2013/07/creating-good-looking-survival-curves-the-ggsurv-function/
ggsurv <- function(s, CI = 'def', plot.cens = T, surv.col = 'gg.def',
                   cens.col = 'red', lty.est = 1, lty.ci = 2,
                   cens.shape = 3, back.white = F, xlab = 'Time',
                   ylab = 'Survival', main = ''){
  
  library(ggplot2)
  strata <- ifelse(is.null(s$strata) ==T, 1, length(s$strata))
  stopifnot(length(surv.col) == 1 | length(surv.col) == strata)
  stopifnot(length(lty.est) == 1 | length(lty.est) == strata)
  
  ggsurv.s <- function(s, CI = 'def', plot.cens = T, surv.col = 'gg.def',
                       cens.col = 'red', lty.est = 1, lty.ci = 2,
                       cens.shape = 3, back.white = F, xlab = 'Time',
                       ylab = 'Survival', main = ''){
    
    dat <- data.frame(time = c(0, s$time),
                      surv = c(1, s$surv),
                      up = c(1, s$upper),
                      low = c(1, s$lower),
                      cens = c(0, s$n.censor))
    dat.cens <- subset(dat, cens != 0)
    
    col <- ifelse(surv.col == 'gg.def', 'black', surv.col)
    
    pl <- ggplot(dat, aes(x = time, y = surv)) +
      xlab(xlab) + ylab(ylab) + ggtitle(main) +
      geom_step(col = col, lty = lty.est)
    
    pl <- if(CI == T | CI == 'def') {
      pl + geom_step(aes(y = up), color = col, lty = lty.ci) +
        geom_step(aes(y = low), color = col, lty = lty.ci)
    } else (pl)
    
    pl <- if(plot.cens == T & length(dat.cens) > 0){
      pl + geom_point(data = dat.cens, aes(y = surv), shape = cens.shape,
                      col = cens.col)
    } else if (plot.cens == T & length(dat.cens) == 0){
      stop ('There are no censored observations')
    } else(pl)
    
    pl <- if(back.white == T) {pl + theme_bw()
    } else (pl)
    pl
  }
  
  ggsurv.m <- function(s, CI = 'def', plot.cens = T, surv.col = 'gg.def',
                       cens.col = 'red', lty.est = 1, lty.ci = 2,
                       cens.shape = 3, back.white = F, xlab = 'Time',
                       ylab = 'Survival', main = '') {
    n <- s$strata
    
    groups <- factor(unlist(strsplit(names
                                     (s$strata), '='))[seq(2, 2*strata, by = 2)])
    gr.name <-  unlist(strsplit(names(s$strata), '='))[1]
    gr.df <- vector('list', strata)
    ind <- vector('list', strata)
    n.ind <- c(0,n); n.ind <- cumsum(n.ind)
    for(i in 1:strata) ind[[i]] <- (n.ind[i]+1):n.ind[i+1]
    
    for(i in 1:strata){
      gr.df[[i]] <- data.frame(
        time = c(0, s$time[ ind[[i]] ]),
        surv = c(1, s$surv[ ind[[i]] ]),
        up = c(1, s$upper[ ind[[i]] ]),
        low = c(1, s$lower[ ind[[i]] ]),
        cens = c(0, s$n.censor[ ind[[i]] ]),
        group = rep(groups[i], n[i] + 1))
    }
    
    dat <- do.call(rbind, gr.df)
    dat.cens <- subset(dat, cens != 0)
    
    pl <- ggplot(dat, aes(x = time, y = surv, group = group)) +
      xlab(xlab) + ylab(ylab) + ggtitle(main) +
      geom_step(aes(col = group, lty = group))
    
    col <- if(length(surv.col == 1)){
      scale_colour_manual(name = gr.name, values = rep(surv.col, strata))
    } else{
      scale_colour_manual(name = gr.name, values = surv.col)
    }
    
    pl <- if(surv.col[1] != 'gg.def'){
      pl + col
    } else {pl + scale_colour_discrete(name = gr.name)}
    
    line <- if(length(lty.est) == 1){
      scale_linetype_manual(name = gr.name, values = rep(lty.est, strata))
    } else {scale_linetype_manual(name = gr.name, values = lty.est)}
    
    pl <- pl + line
    
    pl <- if(CI == T) {
      if(length(surv.col) > 1 && length(lty.est) > 1){
        stop('Either surv.col or lty.est should be of length 1 in order
             to plot 95% CI with multiple strata')
      }else if((length(surv.col) > 1 | surv.col == 'gg.def')[1]){
        pl + geom_step(aes(y = up, color = group), lty = lty.ci) +
          geom_step(aes(y = low, color = group), lty = lty.ci)
      } else{pl +  geom_step(aes(y = up, lty = group), col = surv.col) +
          geom_step(aes(y = low,lty = group), col = surv.col)}
    } else {pl}
    
    
    pl <- if(plot.cens == T & length(dat.cens) > 0){
      pl + geom_point(data = dat.cens, aes(y = surv), shape = cens.shape,
                      col = cens.col)
    } else if (plot.cens == T & length(dat.cens) == 0){
      stop ('There are no censored observations')
    } else(pl)
    
    pl <- if(back.white == T) {pl + theme_bw()
    } else (pl)
    pl
  }
  pl <- if(strata == 1) {ggsurv.s(s, CI , plot.cens, surv.col ,
                                  cens.col, lty.est, lty.ci,
                                  cens.shape, back.white, xlab,
                                  ylab, main)
  } else {ggsurv.m(s, CI, plot.cens, surv.col ,
                   cens.col, lty.est, lty.ci,
                   cens.shape, back.white, xlab,
                   ylab, main)}
  pl
}
```

```{r, echo=F}
# Load and join data
transitioned <- read.csv(file="transitioned.csv", header=T)
censored <- read.csv(file="censored.csv", header=T)
full <- rbind(transitioned, censored)

# Recode the event column -- otherwise it is treated incorrectly 
full$Partial_code_ff <- as.numeric(full$Partial_code_ff)    # Coerce the event variable to numeric
full$event <- ifelse(full$Partial_code_ff == 1, 1, 0)

# Coerce date columns to date types
longFormat = "%d/%m/%Y"
shortFormat = "%d/%m/%y"
full$Socio.Econdate <- as.character(full$Socio.Econdate)
full$Socio.Econdate <- ifelse(full$Socio.Econdate != "", full$Socio.Econdate, NA)

longYear <- grep(pattern = ".+\\d{4}$", x=full$Socio.Econdate)
shortYear <- !(seq(1, nrow(full)) %in% longYear)

long <- full[longYear, ]
short <- full[shortYear, ]

long$Socio.Econdate <- as.Date(long$Socio.Econdate, format=longFormat)
short$Socio.Econdate <- as.Date(short$Socio.Econdate, format=shortFormat)

full <- rbind(long, short)
```

# Introduction

The following is a full report on our data analysis project for the course PSTAT 196: Projects in Actuarial Science. Our analysis was completed during the Spring Quarter of 2017 under the supervision of Professor Ian Duncan and graduate student Shannon ???????? at The University of California, Santa Barbara.

# About the Data

Our dataset comes from a longevity study performed in the United Kingdom from ???? to ?????. Our team's subset of the original data is concerned only with high-risk patients developing severe hyper-tension. All participants in our dataset were already diagnosed with moderate hypertension. Therefore, the task was to model the time until diagnosis of sever hypertension--which lends itself to a classic Survival Analysis problem. Our dataset contains ???? observations and ???? variables. A complete breakdown of the the variables is provided below.

  \begin{center} 
  \text{Breakdown of Covariates:} \\
  \end{center}
Name              | Explanation                                         | Range
-------------     | -------------                                       | -------------
UNQID             | A unique ID for each individual                     | 
Sex               | The patient's sex                                   | 
Socio-Economic    | A categorical range indicating economic status      | 1: Affluent --> 5: Deprived
Socio-Econdate    | The date of the patient's economic evaluation       | 
EventDate         | The patient's event date                            | 
BMI               | The Body Mass Index of the individual               | 
Alcohol           | A binary indicator for drinking habits              | 1: Drinker, 0: Non-Drinker
Cigar             | A binary indicator for smoking habits               | 1: Smoker, 0: Non-Smoker
YOB               | The year of birth of the individual                 | 
Duration          | Time in days spent in the study                     | [0, ???]
Partial_code_pre  | Enter code                                          | Always 2000
Partial_code_ff   | Transition Code                                     | 2000 := Censored, 
.                 |    .                                                | 3000 := Transitioned
Age_Pre           | Age upon entry to the study                         |
Age_Post          | Age at the EventDate                                |

As you can see, some variables (such as YOB, duration, Age\_Pre, Age\_Post) are redundant. When our team began the modeling phase, we did not use every available covariate listed in the above table.

# Objectives
Our team set the following objectives to complete by the end of the quarter.

  1. Thoroughly explore the dataset for discrepancies or interesting trends
    + Make adjustments as necessary
  2. Fit a Cox-PH model to the data
    + Test model assumptions through Schoenfeld Residuals and Log-Log plots
    + Narrow model to the most significant predictors
  3. Attempt k-fold cross validation of the decided Cox model
  4. If time allows, we chose to pursue the following as well:
    + Non-parametric modeling techniques

# Exploratory Analysis


## Tabluar Analysis

it should be right here 

```{r, echo=F, results="asis", message=FALSE}
table.sex <- rbind(table(transitioned$sex), # Summarizing sex counts
                   table(censored$sex), 
                   table(full$sex))

# Show row percentages of sex
table.sex.prop <- as.data.frame(as.matrix(round(prop.table(table.sex, 1), digits = 3))) 

rownames(table.sex.prop) <- c("Transitioned","Censored","All")
colnames(table.sex.prop) <- c("Male","Female")

rownames(table.sex) <- c("Transitioned","Censored","All")
colnames(table.sex) <- c("Male","Female")

table.sex <- as.data.frame(as.matrix(table.sex))

print(xtable(table.sex, type="html", file="sex.tex", floating=F))
```


```{r, echo = F, results="asis"}
# Socio-economic table

table.socio <- rbind(table(transitioned$Socio.Economic),
                     table(censored$Socio.Economic),
                     table(full$Socio.Economic)) #Summarizing socio.economic status counts
#table.socio <- as.data.frame.matrix(table.socio) #Convert the table to a data frame
#table.socio$median <- c(median(transitioned$Socio.Economic),
#                      median(censored$Socio.Economic),
#                      median(full$Socio.Economic)) #Add a mean colume to the data frame
rownames(table.socio) <- c("Transitioned","Censored","All")
table.socio.prop <- round(prop.table(table.socio, 1), 3)

#print(kable(list(table.socio, table.socio.prop)))
```

```{r, echo =F}
# BMI table
table.BMI <- rbind(summary(transitioned$BMInew),
                   summary(censored$BMInew),
                   summary(full$BMInew)) #Summarizing the BMI
rownames(table.BMI) <- c("Trasnsitioned","Censored","All")
#kable(table.BMI)
```

## Discrepancies

Our team quickly found some *very* concerning BMI values. Some ranging to as high as 66000, and some as low as 10. However, a reasonable range for average BMI values is between 18 and 60. We concluded that this was likely the result of an error during data entry or data transfer. Luckily, there were only ????? records that were outside of [15, 100], so we opted to remove those observations that lie outside of that range. We decided on 100 as the upper limit because it *is* possible for a human to have a BMI close to 100. Furthurmore, our data is concerned with those that already developed moderate hyptertension. So it is absolutely possible that an individual has a BMI between 60 and 100.

Next, we found that there *are* some redundant records for a single individual (multiple occurances of a single UNQID). This is because an individual may have had their economic status re-evaluated at some point during the study. Luckily this accounted for only a small set of the data: roughly 300 records. Our team decided to keep only the earliest records and drop any duplicate record with the re-evaluated socioeconomic status.

```{r}
# Remove BMI outliers
new1 <- full[(full$BMInew > 15 && full$BMInew < 100), ]

# Remove duplicate observations, retain earliest record
ordered <- new1 %>%
              arrange(Socio.Econdate)

duplicates <- duplicated(ordered$UNQID_tmp)
new2 <- ordered[!duplicates, ]
```

## Further Analysis



# Modeling

